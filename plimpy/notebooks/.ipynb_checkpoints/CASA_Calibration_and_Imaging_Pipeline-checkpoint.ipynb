{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make This Damn Pipeline Work\n",
    "\n",
    "The goal to start over with something that we know works since something I'm doing doesn't work. This notebook will be broken up into 3 parts\n",
    "\n",
    "1) Calibrate xx data to GLEAM image cube\n",
    "\n",
    "2) Calibrate 4-pol data to GLEAM image cube\n",
    "\n",
    "3) Calibrate 4-pol data to GSM2008 image cube?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python --version\n",
    "**Python 3.7.1**\n",
    "\n",
    "ipython --version\n",
    "**7.3.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "import pyuvdata.utils as uvutils\n",
    "import copy\n",
    "import operator\n",
    "import subprocess\n",
    "import os\n",
    "import sys,shutil\n",
    "import glob\n",
    "import yaml\n",
    "import json\n",
    "import itertools\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from pyuvdata import UVData\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict as odict\n",
    "from astropy.time import Time\n",
    "from functools import reduce\n",
    "\n",
    "sys.path.insert(0,'/Users/tashaleebillings/')\n",
    "import casa_imaging\n",
    "sys.path.insert(0,'/Users/tashaleebillings/casa_imaging/casa_imaging/')\n",
    "import casa_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in [\"pyuvdata\", \"numpy\"]:\n",
    "    try:\n",
    "        _mdl = import_module(module)\n",
    "    except ModuleNotFoundError:\n",
    "        pass\n",
    "    \n",
    "    if hasattr(_mdl, 'version'):\n",
    "        gh = getattr(_mdl.version, 'git_hash', None)\n",
    "    print(\"Module {:<11}....\\tVersion {:<7}.......\\tGit {}\".format(module, _mdl.__version__, gh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Calibrate XX data to GLEAM Image Cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse YAML File\n",
    "\n",
    "You have some yaml file with information about different variables that can be read into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------                                                            \n",
    "# Parse YAML Configuration File                                                                                                             \n",
    "#-------------------------------------------------------------------------------                                                            \n",
    "# Get config and load dictionary                                                                                                            \n",
    "config = '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/NK_CASA_Calibration_and_Imaging_skycal_params.yaml'\n",
    "cf = utils.load_config(config)\n",
    "\n",
    "# Consolidate IO, data and analysis parameter dictionaries                                                                                  \n",
    "params = odict(list(cf['io'].items()) + list(cf['data'].items()) + list(cf['analysis'].items()))\n",
    "assert (len(params) == len(cf['io']) + len(cf['data']) + len(cf['analysis'])), \"Repeated parameters found within the scope of io, data and analysis dicts\"\n",
    "               \n",
    "# Get algorithm dictionary                                                                                                                  \n",
    "algs = cf['algorithm']\n",
    "datafile = os.path.join(params['data_root'], params['data_file'])\n",
    "\n",
    "# Get parameters used globally in the pipeline                                                                                              \n",
    "verbose = params['verbose']\n",
    "overwrite = params['overwrite']\n",
    "casa = params['casa'].split() + params['casa_flags'].split()\n",
    "point_ra = params['point_ra']\n",
    "longitude = params['longitude']\n",
    "latitude = params['latitude']\n",
    "out_dir = params['out_dir']\n",
    "\n",
    "# Change to working dir                                                                                                                     \n",
    "nos.chdir(params['work_dir'])\n",
    "\n",
    "# Open a logfile                                                                                                                            \n",
    "logfile = os.path.join(out_dir, params['logfile'])\n",
    "if os.path.exists(logfile) and params['overwrite'] == False:\n",
    "    raise IOError(\"logfile {} exists and overwrite == False, quitting pipeline...\".format(logfile))\n",
    "lf = open(logfile, \"w\")\n",
    "if params['joinlog']:\n",
    "    ef = lf\n",
    "else:\n",
    "    ef = open(os.path.join(params['out_dir'], params['errfile']), \"w\")\n",
    "casa += ['--logfile', logfile]\n",
    "sys.stdout = lf\n",
    "sys.stderr = ef\n",
    "\n",
    "# Setup (Small) Global Variable Dictionary                                                                                                  \n",
    "varlist = ['datafile', 'verbose', 'overwrite', 'out_dir', 'casa', 'point_ra', 'longitude',\n",
    "           'latitude', 'lf', 'gaintables']\n",
    "def global_vars(varlist=[]):\n",
    "    d = []\n",
    "    for v in varlist:\n",
    "        try:\n",
    "            d.append((v, globals()[v]))\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return dict(d)\n",
    "\n",
    "# Print out parameter header                                                                                                                \n",
    "time = datetime.utcnow()\n",
    "utils.log(\"Starting skycal_pipe.py on {}\\n{}\\n\".format(time, '-'*60),\n",
    "             f=lf, verbose=verbose)\n",
    "_cf = copy.copy(cf)\n",
    "_cf.pop('algorithm')\n",
    "utils.log(json.dumps(_cf, indent=1) + '\\n', f=lf, verbose=verbose)\n",
    "\n",
    "# Setup a dict->object converter                                                                                                            \n",
    "class Dict2Obj:\n",
    "    def __init__(self, **entries):\n",
    "        self.__dict__.update(entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data to be Converted to Measurment Set\n",
    "\n",
    "If it is determined that the file(s) are not MS then for each polarization, we loop through each file to see which ones are closest to the correct source LST and then cut the fill down from 10mins to 4mins and then writes it as a new MS file with an updataed JD name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------                                                            \n",
    "# Search for a Source and Prepare Data for MS Conversion                                                                                    \n",
    "#-------------------------------------------------------------------------------                                                            \n",
    "if params['prep_data']:\n",
    "    # start block                                                                                                                           \n",
    "    time = datetime.utcnow()\n",
    "    utils.log(\"\\n{}\\n...Starting PREP_DATA: {}\\n\".format(\"-\"*60, time),\n",
    "                 f=lf, verbose=verbose)\n",
    "    utils.log(json.dumps(algs['prep_data'], indent=1) + '\\n', f=lf, verbose=verbose)\n",
    "    p = Dict2Obj(**algs['prep_data'])\n",
    "\n",
    "    # Check if datafile is already MS\n",
    "    sys.path.insert(0,'/Users/tashaleebillings/casa_imaging/scripts/')\n",
    "    import source2file\n",
    "    \n",
    "    if os.path.splitext(datafile)[1] in ['.ms','.MS']:\n",
    "        # get transit times                                                                                                                 \n",
    "        (lst, transit_jd, utc_range, utc_center, source_files,\n",
    "         source_utc_range) = source2file.source2file(point_ra, lon=longitude, lat=latitude,\n",
    "                                                     duration=p.duration, start_jd=p.start_jd, get_filetimes=False,\n",
    "                                                     verbose=verbose)\n",
    "        utils.log(\"...the file {} is already a CASA MS, skipping rest of PREP_DATA\".format(datafile), f=lf, verbose=verbose)\n",
    "        timerange = utc_range\n",
    "\n",
    "    else:\n",
    "        # Iterate over polarizations                                                                                                        \n",
    "        if p.pols is None: p.pols = [None]\n",
    "        uvds = []\n",
    "        for pol in p.pols:\n",
    "            if pol is None:\n",
    "                pol = ''\n",
    "            else:\n",
    "                utils.log(\"...working on {} polarization\".format(pol), f=lf, verbose=verbose)\n",
    "                pol = '.{}.'.format(pol)\n",
    "\n",
    "            # glob-parse the data file / template                                                                                           \n",
    "            datafiles = [df for df in glob.glob(datafile) if pol in df]\n",
    "            assert len(datafiles) > 0, \"Searching for {} with pol {} but found no files...\".format(datafile, pol)\n",
    "\n",
    "            # get transit times                                                                                                             \n",
    "            import source2file\n",
    "            (lst, transit_jd, utc_range, utc_center, source_files,\n",
    "             source_utc_range) = source2file.source2file(point_ra, lon=longitude, lat=latitude,\n",
    "                                                         duration=p.duration, start_jd=p.start_jd, get_filetimes=p.get_filetimes,\n",
    "                                                         verbose=verbose, jd_files=copy.copy(datafiles))\n",
    "            timerange = utc_range\n",
    "\n",
    "            # ensure source_utc_range and utc_range are similar       \n",
    "            \n",
    "            if source_utc_range is not None:\n",
    "                utc_range_start = utc_range.split('~')[0].strip('\"').split('/')\n",
    "                utc_range_start = map(int, utc_range_start[:-1] + utc_range_start[-1].split(':'))\n",
    "                utc_range_start = Time(datetime(*utc_range_start), format='datetime').jd\n",
    "                source_utc_range_start = source_utc_range.split('~')[0].strip('\"').split('/')\n",
    "                source_utc_range_start = map(int, source_utc_range_start[:-1] + source_utc_range_start[-1].split(':'))\n",
    "                source_utc_range_start = Time(datetime(*source_utc_range_start), format='datetime').jd\n",
    "                # if difference is larger than 1 minute,                                                                                    \n",
    "                # then probably the correct files were not found                                                                            \n",
    "                if np.abs(utc_range_start - source_utc_range_start) * 24 * 60 > 1:\n",
    "                    utils.log(\"Warning: Difference between theoretical transit time and transit time \" \\\n",
    "                        \"deduced from files found is larger than 1-minute: probably the correct \" \\\n",
    "                        \"files were not found because the correct files did not exist under the \" \\\n",
    "                        \"data template {}\".format(datafile), f=lf, verbose=verbose)\n",
    "                timerange = source_utc_range\n",
    "\n",
    "            # load data into UVData         \n",
    "            utils.log(\"...loading data\", f=lf, verbose=verbose)\n",
    "            _uvds = []\n",
    "            for sf in list(source_files):\n",
    "                # read data                                                                                                                 \n",
    "                _uvd = UVData()\n",
    "                _uvd.read(sf, antenna_nums=p.antenna_nums)\n",
    "                \n",
    "                # read flagfile if fed                                                                                                      \n",
    "                if p.flag_ext != \"\":\n",
    "                    flagfile = glob.glob(\"{}{}\".format(sf, p.flag_ext))\n",
    "                    if len(flagfile) == 1:\n",
    "                        utils.log(\"...loading and applying flags {}\".format(flagfile[0]), f=lf, verbose=verbose)\n",
    "                        ff = np.load(flagfile[0])\n",
    "                        _uvd.flag_array += ff['flag_array']\n",
    "\n",
    "                # append to list                                                                                                            \n",
    "                _uvds.append(_uvd)\n",
    "\n",
    "            # concatenate source files                                                                                                      \n",
    "            uvd = reduce(operator.add, _uvds)\n",
    "\n",
    "            # isolate only relevant times                                                                                                   \n",
    "            times = np.unique(uvd.time_array)\n",
    "            times = times[np.abs(times-transit_jd) < (p.duration / (24. * 60. * 2))]\n",
    "            assert len(times) > 0, \"No times found in source_files {} given transit JD {} and duration {}\".format(source_files, transit_jd,\\\n",
    " p.duration)\n",
    "            uvd.select(times=times)\n",
    "\n",
    "            # append                                                                                                                        \n",
    "            uvds.append(uvd)\n",
    "\n",
    "        # concatenate uvds                                                                                                                  \n",
    "        uvd = reduce(operator.add, uvds) #can be issue in python 3\n",
    "\n",
    "        # get output filepath w/o uvfits extension if provided                                                                              \n",
    "        outfile = os.path.join(params['out_dir'], p.outfile.format(uvd.time_array.min()))\n",
    "        if os.path.splitext(outfile)[1] == '.uvfits':\n",
    "            outfile = os.path.splitext(outfile)[0]\n",
    "\n",
    "        # renumber antennas (and antenna names!) if above 254                                                                               \n",
    "        if uvd.antenna_numbers.max() > 254:\n",
    "            large_ant_nums = sorted(list(uvd.antenna_numbers[np.where(uvd.antenna_numbers > 254)[0]]))\n",
    "            new_nums = sorted(list(set(range(255)) - set(uvd.antenna_numbers)))\n",
    "            if len(new_nums) < len(large_ant_nums):\n",
    "                raise ValueError('too many antennas in dataset, cannot renumber all below 255')\n",
    "            new_nums = new_nums[-1 * len(large_ant_nums):]\n",
    "            renumber_dict = dict(list(zip(large_ant_nums, new_nums)))\n",
    "\n",
    "            history = ''\n",
    "            name_prefix = os.path.commonprefix(uvd.antenna_names)\n",
    "            for ant_in, ant_out in renumber_dict.items():\n",
    "                if verbose:\n",
    "                    msg = \"renumbering {a1} to {a2}\".format(a1=ant_in, a2=ant_out)\n",
    "                    print(msg)\n",
    "                history += '{}\\n'.format(msg)\n",
    "\n",
    "                wh_ant_num = np.where(uvd.antenna_numbers == ant_in)[0]\n",
    "                wh_ant1_arr = np.where(uvd.ant_1_array == ant_in)[0]\n",
    "                wh_ant2_arr = np.where(uvd.ant_2_array == ant_in)[0]\n",
    "\n",
    "                uvd.antenna_numbers[wh_ant_num] = ant_out\n",
    "                uvd.antenna_names[wh_ant_num[0]] = \"RN{:d}\".format(ant_out)\n",
    "                uvd.ant_1_array[wh_ant1_arr] = ant_out\n",
    "                uvd.ant_2_array[wh_ant2_arr] = ant_out\n",
    "\n",
    "            uvd.baseline_array = uvd.antnums_to_baseline(uvd.ant_1_array, uvd.ant_2_array)\n",
    "            uvd.history = '{}\\n{}'.format(history, uvd.history)\n",
    "            uvd.check()\n",
    "\n",
    "            # write renumbering dictionary to .npz                                                                                          \n",
    "            np.savez(\"{}.renumber.npz\".format(outfile),\n",
    "                     renumber=dict(zip(renumber_dict.values(), renumber_dict.keys())),\n",
    "                     history=\"Access dictionary via f['renumber'].item()\")\n",
    "\n",
    "        # write to file                                                                                                                     \n",
    "        if uvd.phase_type == 'phased':\n",
    "            # write uvfits                                                                                                                  \n",
    "            uvfits_outfile = outfile + '.uvfits'\n",
    "            if not os.path.exists(uvfits_outfile) or overwrite:\n",
    "                utils.log(\"...writing {}\".format(uvfits_outfile), f=lf, verbose=verbose)\n",
    "                uvd.write_uvfits(uvfits_outfile, spoof_nonessential=True)\n",
    "            # unphase to drift                                                                                                              \n",
    "            uvd.unphase_to_drift()\n",
    "            # write miriad                                                                                                                  \n",
    "            if not os.path.exists(outfile) or overwrite:\n",
    "                utils.log(\"...writing {}\".format(outfile), f=lf, verbose=verbose)\n",
    "                uvd.write_miriad(outfile, clobber=True)\n",
    "        elif uvd.phase_type == 'drift':\n",
    "            # write miriad                                                                                                                  \n",
    "            if not os.path.exists(outfile) or overwrite:\n",
    "                utils.log(\"...writing {}\".format(outfile), f=lf, verbose=verbose)\n",
    "                uvd.write_miriad(outfile, clobber=True)\n",
    "            # write uvfits                                                                                                                  \n",
    "            uvfits_outfile = outfile + '.uvfits'\n",
    "            if not os.path.exists(uvfits_outfile) or overwrite:\n",
    "                uvd.phase_to_time(Time(transit_jd, format='jd'))\n",
    "                utils.log(\"...writing {}\".format(uvfits_outfile), f=lf, verbose=verbose)\n",
    "                uvd.write_uvfits(uvfits_outfile, spoof_nonessential=True)\n",
    "                \n",
    "        # convert the uvfits file to ms                                                                                                     \n",
    "        ms_outfile = outfile + '.ms'\n",
    "        utils.log(\"...converting to Measurement Set\")\n",
    "        if not os.path.exists(ms_outfile) or overwrite:\n",
    "            if os.path.exists(ms_outfile):\n",
    "                shutil.rmtree(ms_outfile)\n",
    "            utils.log(\"...writing {}\".format(ms_outfile), f=lf, verbose=verbose)\n",
    "            ecode = subprocess.check_call(casa + [\"-c\", \"importuvfits('{}', '{}')\".format(uvfits_outfile, ms_outfile)])\n",
    "\n",
    "        # overwrite relevant parameters for downstream analysis                                                                             \n",
    "        datafile = ms_outfile\n",
    "\n",
    "        del uvds, uvd\n",
    "\n",
    "    # overwrite downstream parameters                                                                                                       \n",
    "    algs['gen_model']['time'] = transit_jd\n",
    "\n",
    "    # end block                                                                                                                             \n",
    "    time2 = datetime.utcnow()\n",
    "    utils.log(\"...finished PREP_DATA: {:d} sec elapsed\".format(utils.get_elapsed_time(time, time2)), f=lf, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Flux Model\n",
    "\n",
    "This subsection was taken from Nick's pipeline script. \"Generate Flux Model\" is a section with a couple of functions that help feed in the args params to a CASA python script \"complist_gleam.py\" that builds the model from the gleam components and saves it as a CASA readable image file ('.image', '.fits').\n",
    "\n",
    "I decided to not actually run this section. Instead I wanted look more closely at the \"complist_gleam.py\" script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------                                                               \n",
    "# Generate Flux Model                                                                                                                          \n",
    "#-------------------------------------------------------------------------------                                                               \n",
    "\n",
    "# Make a Model Generation Function                                                                                                             \n",
    "def gen_model(**kwargs):\n",
    "    p = Dict2Obj(**kwargs)\n",
    "    utils.log(\"\\n{}\\n...Generating a Flux Model\", f=p.lf, verbose=p.verbose)\n",
    "\n",
    "    # compile complist_gleam.py command                                                                                                        \n",
    "    cmd = casa + [\"-c\", \"/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/complist_gleam.py\"]\n",
    "    cmd += ['--gleamfile', p.gleamfile,'--point_ra', p.point_ra, '--point_dec', p.latitude, \n",
    "            '--outdir', p.out_dir, '--imsize', p.imsize, '--radius', p.radius, \n",
    "            '--min_flux', p.min_flux, '--freqs', p.freqs, '--cell', p.cell]\n",
    "    if p.image:\n",
    "        cmd += ['--image']\n",
    "    if p.use_peak:\n",
    "        cmd += ['--use_peak']\n",
    "    if p.overwrite:\n",
    "        cmd += ['--overwrite']\n",
    "    if hasattr(p, 'regions'):\n",
    "        cmd += ['--regions', p.regions, '--exclude', '--region_radius', p.region_radius]\n",
    "    if hasattr(p, 'file_ext'):\n",
    "        cmd += ['--ext', p.file_ext]\n",
    "    else:\n",
    "        p.file_ext = ''\n",
    "    cmd = map(str, cmd)\n",
    "    ecode = subprocess.call(cmd)\n",
    "\n",
    "    modelstem = os.path.join(p.out_dir,\"{}_model.cl\".format(os.path.basename(p.gleamfile[:-5])))\n",
    "    model_base = os.path.splitext(modelstem)[0]\n",
    "    fitsname = \"{}.fits\".format(model_base)\n",
    "    if p.image:\n",
    "        model_base += \".image\"\n",
    "\n",
    "    # pbcorrect                                                                                                                                \n",
    "    if p.pbcorr:\n",
    "        utils.log(\"...applying PB to model\", f=p.lf, verbose=p.verbose)\n",
    "        assert p.image, \"Cannot pbcorrect flux model without image == True\"\n",
    "        cmd = [\"/Users/tashaleebillings/casa_imaging/scripts/pbcorr.py\", \"--lon\", p.longitude, \"--lat\", p.latitude, \"--time\", p.time, \"--pols\"] \\\n",
    "               + [uvutils.polstr2num(pol) for pol in p.pols] \\\n",
    "               + [\"--outdir\", p.out_dir, \"--multiply\", \"--beamfile\", p.beamfile, \"fitsfiles\", fitsname]\n",
    "        if p.overwrite:\n",
    "            cmd.append(\"--overwrite\")\n",
    "        #cmd.append(modelstem + '.fits')\n",
    "\n",
    "        # generate component list and / or image cube flux model                                                                               \n",
    "        cmd = map(str, cmd)\n",
    "        ecode = subprocess.call(cmd)\n",
    "        pbcorr_modelstem = os.path.join(p.out_dir, modelstem)\n",
    "\n",
    "        # importfits                                                                                                                           \n",
    "        cmd = p.casa + [\"-c\", \"importfits('{}', '{}', overwrite={})\".format(pbcorr_modelstem + '.pbcorr.fits', pbcorr_modelstem + '.pbcorr.image', p.overwrite)]\n",
    "        ecode = subprocess.call(cmd)\n",
    "        pbcorr_model = pbcorr_modelstem + \".pbcorr.image\"\n",
    "\n",
    "    return pbcorr_model\n",
    "\n",
    "if params['gen_model']:\n",
    "    # start block                                                                                                                              \n",
    "    time = datetime.utcnow()\n",
    "    utils.log(\"\\n{}\\n...Starting GEN_MODEL: {}\\n\".format(\"-\"*60, time),\n",
    "                 f=lf, verbose=verbose)\n",
    "    utils.log(json.dumps(algs['gen_model'], indent=1) + '\\n', f=lf, verbose=verbose)\n",
    "\n",
    "    # Generate Model                                                                                                                           \n",
    "    model = gen_model(**dict(list(algs['gen_model'].items()) + list(global_vars(varlist).items())))\n",
    "\n",
    "    # update di_cal model path                                                                                                                 \n",
    "    algs['di_cal']['model'] = model\n",
    "\n",
    "    # end block                                                                                                                                \n",
    "    time2 = datetime.utcnow()\n",
    "    utils.log(\"...finished GEN_MODEL: {:d} sec elapsed\".format(utils.get_elapsed_time(time, time2)), f=lf, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_gleam = fits.open(\"/Users/tashaleebillings/Desktop/data/small_gleam.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XTENSION= 'BINTABLE'           / binary table extension                         \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    2 / number of array dimensions                     \n",
       "NAXIS1  =                   73 / length of dimension 1                          \n",
       "NAXIS2  =               158816 / length of dimension 2                          \n",
       "PCOUNT  =                    0 / number of group parameters                     \n",
       "GCOUNT  =                    1 / number of groups                               \n",
       "TFIELDS =                   10 / number of table fields                         \n",
       "TTYPE1  = 'GLEAM   '                                                            \n",
       "TFORM1  = '14A     '                                                            \n",
       "TDISP1  = 'A14     '                                                            \n",
       "TTYPE2  = 'RAJ2000 '                                                            \n",
       "TFORM2  = 'D       '                                                            \n",
       "TUNIT2  = 'deg     '                                                            \n",
       "TDISP2  = 'F10.6   '                                                            \n",
       "TTYPE3  = 'DEJ2000 '                                                            \n",
       "TFORM3  = 'D       '                                                            \n",
       "TUNIT3  = 'deg     '                                                            \n",
       "TDISP3  = 'F10.6   '                                                            \n",
       "TTYPE4  = 'Fp151   '                                                            \n",
       "TFORM4  = 'D       '                                                            \n",
       "TUNIT4  = 'Jy/beam '                                                            \n",
       "TDISP4  = 'F11.6   '                                                            \n",
       "TTYPE5  = 'Fint151 '                                                            \n",
       "TFORM5  = 'D       '                                                            \n",
       "TUNIT5  = 'Jy      '                                                            \n",
       "TDISP5  = 'F11.6   '                                                            \n",
       "TTYPE6  = 'alpha   '                                                            \n",
       "TFORM6  = 'D       '                                                            \n",
       "TDISP6  = 'F9.6    '                                                            \n",
       "TTYPE7  = 'Fpwide  '                                                            \n",
       "TFORM7  = 'D       '                                                            \n",
       "TUNIT7  = 'Jy/beam '                                                            \n",
       "TDISP7  = 'F10.6   '                                                            \n",
       "TTYPE8  = 'Fintwide'                                                            \n",
       "TFORM8  = 'D       '                                                            \n",
       "TUNIT8  = 'Jy      '                                                            \n",
       "TDISP8  = 'F10.6   '                                                            \n",
       "TTYPE9  = 'eabsFpct'                                                            \n",
       "TFORM9  = 'I       '                                                            \n",
       "TUNIT9  = '%       '                                                            \n",
       "TDISP9  = 'I2      '                                                            \n",
       "TTYPE10 = 'efitFpct'                                                            \n",
       "TFORM10 = 'B       '                                                            \n",
       "TUNIT10 = '%       '                                                            \n",
       "TDISP10 = 'I1      '                                                            "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_gleam[1].header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FITS_rec([('J210214-503334', 315.56118806, -50.55952806, 0.070516, 0.09502 ,       nan, 0.054038, 0.079292, 8, 2),\n",
       "          ('J210145-503246', 315.43759194, -50.54626111, 0.065017, 0.075701, -1.070268, 0.051587, 0.062953, 8, 2),\n",
       "          ('J210443-503427', 316.183075  , -50.57444   , 0.093348, 0.096954, -0.228791, 0.116614, 0.122704, 8, 2),\n",
       "          ...,\n",
       "          ('J160542-112733', 241.42691   , -11.45941389, 0.059182, 0.063335, -0.246412, 0.113151, 0.124321, 8, 2),\n",
       "          ('J163130-104322', 247.87745694, -10.72296194, 0.244387, 0.260097, -0.734114, 0.250608, 0.271932, 8, 2),\n",
       "          ('J133637-335724', 204.15570111, -33.95689389, 0.035134, 0.031256,       nan, 0.650765, 0.54306 , 8, 2)],\n",
       "         dtype=(numpy.record, [('GLEAM', 'S14'), ('RAJ2000', '>f8'), ('DEJ2000', '>f8'), ('Fp151', '>f8'), ('Fint151', '>f8'), ('alpha', '>f8'), ('Fpwide', '>f8'), ('Fintwide', '>f8'), ('eabsFpct', '>i2'), ('efitFpct', 'u1')]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(small_gleam[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "hm = fits.open(\"/Users/tashaleebillings/Desktop/data/randsrc_airybeam_Nsrc100_fullband_fullStokesModel.model.fits\")[0].data\n",
    "print(type(hm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, b'Sirius', -1.45, b'A1V') (2, b'Canopus', -0.73, b'F0Ib')\n",
      " (3, b'Rigil Kent', -0.1 , b'G2V')]\n"
     ]
    }
   ],
   "source": [
    "bright = np.rec.array([(1,'Sirius', -1.45, 'A1V'),\n",
    "                       (2,'Canopus', -0.73, 'F0Ib'),\n",
    "                       (3,'Rigil Kent', -0.1, 'G2V')],\n",
    "                      formats='int16,a20,float32,a10',\n",
    "                      names='order,name,mag,Sp')\n",
    "print(bright)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Image Cube From GLEAM Component List\n",
    "\n",
    "Lets take a closer look at \"complist_gleam.py\". The first thing I did was print the parameters to the screen. These are the same ones that were originally stored in the yaml file. I'm doing this so that I can manually feed in this information into \"complist_gleam.py\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Parameters to screen\n",
    "gen_model=list(algs['gen_model'].items())\n",
    "name_gm,values_gm = zip(*gen_model)\n",
    "\n",
    "global_vars = list(global_vars(varlist).items())\n",
    "name_gv, values_gv = zip(*global_vars)\n",
    "\n",
    "names_gmgv = name_gm+name_gv\n",
    "values_gmgv = values_gm+values_gv\n",
    "\n",
    "for i in range(len(names_gmgv)):\n",
    "    print(names_gmgv[i]),\n",
    "    print('='), \n",
    "    print(values_gmgv[i])\n",
    "    \n",
    "\"\"\"\n",
    "#in python 3.x\n",
    "print(\"geeks\", end =\" \") \n",
    "print(\"geeksforgeeks\") \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run \"complist_gleam.py\" in CASA\n",
    "\n",
    "Now that I printed the parameters you can copy and paste them below. When you run the cell it will build a CASA image using the componentlist filled with information from GLEAM and then convert it to a fits image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To be ran in CASA complist_gleam.py\n",
    "import os, shutil, sys\n",
    "import numpy as np\n",
    "import pyfits as fits\n",
    "\n",
    "gleamfile = '/Users/tashaleebillings/casa_imaging/casa_imaging/data/small_gleam.fits'\n",
    "point_ra = 30.05\n",
    "point_dec = -30.7215\n",
    "outdir = '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/'\n",
    "image = True\n",
    "imsize = 512\n",
    "radius = 20\n",
    "min_flux = 0.1\n",
    "use_peak = False\n",
    "freqs = '100,200,1024'\n",
    "cell = '300arcsec'\n",
    "pbcorr = True\n",
    "beamfile = '/Users/tashaleebillings/casa_imaging/casa_imaging/data/HERA_NF_dipole_power.beamfits'\n",
    "time = 2458101.294912982\n",
    "pols = ['xx', 'yy']\n",
    "datafile = '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/zen.2458101.29385.HH.uvR.ms'\n",
    "image = True #'True'\n",
    "overwrite = True\n",
    "regions = None\n",
    "region_radius = None\n",
    "\n",
    "basename = os.path.join(outdir, \"{}_model.cl\".format(os.path.basename(gleamfile)[:-5]))\n",
    "\n",
    "if os.path.exists(basename) and not overwrite:\n",
    "    print(\"{} already exists, not writing...\".format(basename))\n",
    "    sys.exit()\n",
    "\n",
    "# set pointing direction\n",
    "def deg2eq(ra, dec):\n",
    "    _ra = ra / 15.0\n",
    "    ra_h = int(np.floor(_ra))\n",
    "    ra_m = int(np.floor((_ra - ra_h) * 60))\n",
    "    ra_s = int(np.around(((_ra - ra_h) * 60 - ra_m) * 60))\n",
    "    dec_d = int(np.floor(np.abs(dec)) * dec / np.abs(dec))\n",
    "    dec_m = int(np.floor(np.abs(dec - dec_d) * 60.))\n",
    "    dec_s = int(np.abs(dec - dec_d) * 3600 - dec_m * 60)\n",
    "    direction = \"{:02d}h{:02d}m{:02.0f}s {:03d}d{:02d}m{:02.0f}s\".format(ra_h, ra_m, ra_s, dec_d, dec_m, dec_s)\n",
    "    return direction\n",
    "\n",
    "direction = \"J2000 {}\".format(deg2eq(point_ra, point_dec))\n",
    "ref_freq = \"151MHz\"\n",
    "\n",
    "# Select all sources around pointing\n",
    "hdu = fits.open(gleamfile)\n",
    "data = hdu[1].data\n",
    "data_ra = data[\"RAJ2000\"].copy() # 1D array\n",
    "data_dec = data[\"DEJ2000\"].copy() # 1D array\n",
    "\n",
    "# get fluxes\n",
    "if use_peak:\n",
    "    fstr = \"Fp{:d}\"\n",
    "    fluxes = data['Fp151']\n",
    "else:\n",
    "    fstr = \"Fint{:d}\"\n",
    "    fluxes = data['Fint151']\n",
    "\n",
    "# correct for wrapping RA\n",
    "if point_ra < radius:\n",
    "    data_ra[data_ra > point_ra + radius] -= 360.0\n",
    "elif np.abs(360.0 - point_ra) < radius:\n",
    "    data_ra[data_ra < 360.0 - point_ra] += 360.0\n",
    "\n",
    "# select sources\n",
    "ra_dist = np.abs(data_ra - point_ra)\n",
    "dec_dist = np.abs(data_dec - point_dec)\n",
    "dist = np.sqrt(ra_dist**2 + dec_dist**2)\n",
    "select = np.where((dist <= radius) & (fluxes >= min_flux))[0]\n",
    "if len(select) == 0:\n",
    "    raise ValueError(\"No sources found given RA, Dec and min_flux selections.\")\n",
    "print(\"...a total of {} sources were found given RA, Dec and min_flux cuts\".format(len(select)))\n",
    "\n",
    "# if regions provided, load them\n",
    "if regions is not None:\n",
    "    mask_ra, mask_dec = np.loadtxt(regions, dtype=np.float, usecols=(2, 3), unpack=True)\n",
    "    assert region_radius is not None, \"if providing a list of sources, must specify region radius [deg]\"\n",
    "    mask_rad = region_radius\n",
    "\n",
    "# iterate over sources and add to complist\n",
    "select = select[np.argsort(dist[select])]\n",
    "source = \"{name:s}\\t{flux:06.2f}\\t{spix:02.2f}\\t{ra:07.3f}\\t{dec:07.3f}\"\n",
    "sources = []\n",
    "for s in select:\n",
    "    # get source info\n",
    "    flux = fluxes[s]\n",
    "    spix = data['alpha'][s]\n",
    "    s_ra, s_dec = data['RAJ2000'][s], data['DEJ2000'][s]\n",
    "    s_dir = deg2eq(s_ra, s_dec)\n",
    "    name = \"GLEAM {}\".format(s_dir)\n",
    "\n",
    "    # exclude or include if fed regions\n",
    "    if regions is not None:\n",
    "        mask_dists = np.sqrt((mask_ra - s_ra)**2 + (mask_dec - s_dec)**2)\n",
    "        if a.exclude:\n",
    "            if mask_dists.min() < mask_rad:\n",
    "                continue\n",
    "        else:\n",
    "            if mask_dists.min() >= mask_rad:\n",
    "                continue\n",
    "\n",
    "    # if spectral index is a nan, try to derive it by hand\n",
    "    if np.isnan(spix):\n",
    "        frq = np.array([122., 130., 143., 151., 158., 166., 174.])\n",
    "        x = []\n",
    "        xstr = []\n",
    "        for f in frq:\n",
    "            xst = fstr.format(int(f))\n",
    "            if xst in data.dtype.fields:\n",
    "                x.append(f)\n",
    "                xstr.append(xst) # a list of peak or integration names\n",
    "        x = np.asarray(x, dtype=np.float)# array of frq\n",
    "        y = np.log10([data[s][xs] for xs in xstr])\n",
    "        if sum(~np.isnan(y)) < 2:\n",
    "            # skip this source b/c less all but 1 bins are negative or nan...\n",
    "            continue\n",
    "        spix = np.polyfit(np.log10(x)[~np.isnan(y)], y[~np.isnan(y)], deg=1)[0]# returns coeff.\n",
    "\n",
    "        # if this is unreasonable, set to 0\n",
    "        if spix < -3 or spix > 1:\n",
    "            spix = 0\n",
    "\n",
    "    # create component list\n",
    "    cl.addcomponent(label=name, flux=flux, fluxunit=\"Jy\",\n",
    "                    dir=\"J2000 {}\".format(s_dir), freq=ref_freq, shape='point',\n",
    "                    spectrumtype='spectral index', index=spix)\n",
    "    sources.append(source.format(name=name, flux=flux, spix=spix, ra=s_ra, dec=s_dec))\n",
    "\n",
    "# write source list to file\n",
    "print(\"...including {} sources\".format(len(sources)))\n",
    "srcname = \"{}.srcs.tab\".format(basename)\n",
    "print(\"...saving {}\".format(srcname))\n",
    "with open(srcname, \"w\") as f:\n",
    "    f.write(\"# name\\t flux [Jy]\\t spix\\t RA\\t Dec\\n\")\n",
    "    f.write('\\n'.join(sources))\n",
    "\n",
    "# save\n",
    "print(\"...saving {}\".format(basename))\n",
    "if os.path.exists(basename):\n",
    "    shutil.rmtree(basename)\n",
    "cl.rename(basename)\n",
    "\n",
    "# make image\n",
    "if image:\n",
    "    print(\"Making image.\")\n",
    "    # get frequencies\n",
    "    if freqs is None:\n",
    "        Nfreqs = 1\n",
    "        freq = np.array([151.0])\n",
    "    else:\n",
    "        freq = np.linspace(*np.array(freqs.split(',')).astype(np.float), endpoint=False)\n",
    "        Nfreqs = len(freq)\n",
    "\n",
    "    # setup image\n",
    "    imname = \"{}.image\".format(basename)\n",
    "    print(\"...saving {}\".format(imname))\n",
    "    ia.fromshape(imname, [imsize, imsize, 1, Nfreqs], overwrite=True)\n",
    "    cs = ia.coordsys()\n",
    "    cs.setunits(['rad','rad','','Hz'])\n",
    "\n",
    "    # set pixel properties\n",
    "    cell_rad = qa.convert(qa.quantity(cell),\"rad\")['value']\n",
    "    cs.setincrement([-cell_rad, cell_rad], type='direction')\n",
    "    cs.setreferencevalue([qa.convert(direction.split()[1],'rad')['value'], qa.convert(direction.split()[2],'rad')['value']], type=\"direction\")\n",
    "\n",
    "    # set freq properties\n",
    "    qa_freqs = qa.quantity(freq, 'MHz')\n",
    "    cs.setspectral(frequencies=qa_freqs)\n",
    "\n",
    "    # set flux properties, make image, export to fits\n",
    "    ia.setcoordsys(cs.torecord())\n",
    "    ia.setbrightnessunit(\"Jy/pixel\")\n",
    "    ia.modify(cl.torecord(), subtract=False)\n",
    "    fitsname = \"{}.fits\".format(basename)\n",
    "    print(\"...saving {}\".format(fitsname))\n",
    "    exportfits(imagename=imname, fitsimage=fitsname, overwrite=True, stokeslast=False)\n",
    "\n",
    "cl.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Beam Correction\n",
    "\n",
    "Now we need to primary beam correct the model. You can run pbcorr.py but here I copied the script below and used the appropriate parameters from the yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary beam correct out model.\n",
    "import numpy as np\n",
    "import astropy.io.fits as fits\n",
    "import scipy.stats as stats\n",
    "import os, sys, glob, copy, shutil, healpy\n",
    "\n",
    "from astropy import wcs\n",
    "from pyuvdata import UVBeam\n",
    "from scipy import interpolate\n",
    "from astropy.time import Time\n",
    "from astropy import coordinates as crd\n",
    "from astropy import units as u\n",
    "\n",
    "\n",
    "beamfile = '/Users/tashaleebillings/casa_imaging/casa_imaging/data/HERA_NF_dipole_power.beamfits'\n",
    "fitsfiles = ['/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/small_gleam_model.cl.fits']\n",
    "outdir = '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/'\n",
    "ext = None\n",
    "pols = [uvutils.polstr2num(pol) for pol in p.pols]\n",
    "overwrite = True\n",
    "multiply = True\n",
    "lon_t = 21.4286\n",
    "lat_t = -30.7215\n",
    "time_ = 2458101.294912982\n",
    "\n",
    "# load pb\n",
    "if beamfile is not None:\n",
    "    print(\"...loading beamfile {}\".format(beamfile))\n",
    "    # load beam\n",
    "    uvb = UVBeam()\n",
    "    uvb.read_beamfits(beamfile)\n",
    "    # get beam models and beam parameters\n",
    "    beam_maps = np.abs(uvb.data_array[0, 0, :, :, :])\n",
    "    beam_freqs = uvb.freq_array.squeeze() / 1e6\n",
    "    Nbeam_freqs = len(beam_freqs)\n",
    "    beam_nside = healpy.npix2nside(beam_maps.shape[2])\n",
    "\n",
    "    # construct beam interpolation function\n",
    "    def beam_interp_func(theta, phi):\n",
    "        # convert to radians\n",
    "        theta = copy.copy(theta) * np.pi / 180.0\n",
    "        phi = copy.copy(phi) * np.pi / 180.0\n",
    "        shape = theta.shape\n",
    "        # loop over freq, then pol\n",
    "        beam_interp = [[healpy.get_interp_val(m, theta.ravel(), phi.ravel(), lonlat=False).reshape(shape) for m in maps] for maps in beam_maps]\n",
    "        return np.array(beam_interp)\n",
    "\n",
    "# construct pb\n",
    "else: # doesn't matter because we are giving this script a beamfile\n",
    "    # construct beam interpolation function\n",
    "    print(\"...constructing beam from Gaussian models\")\n",
    "    if ew_sig is None or ns_sig is None:\n",
    "        raise AttributeError(\"if beamfile is None, then must feed ew_sig and ns_sig\")\n",
    "    def beam_interp_func(theta, phi):\n",
    "        beam_interp = []\n",
    "        psi_ew = theta * np.cos(phi)\n",
    "        psi_ns = theta * np.sin(phi)\n",
    "        shape = theta.shape\n",
    "        for i, (ews, nss) in enumerate(zip(ew_sig, ns_sig)):\n",
    "            m = stats.multivariate_normal.pdf(np.array([psi_ew.ravel(), psi_ns.ravel()]).T, mean=np.zeros(2),\n",
    "                                          cov=np.array([[ews**2, 0],[0, nss**2]]))\n",
    "            beam_interp.append(m.reshape(shape))\n",
    "        return np.array(beam_interp)\n",
    "    beam_freqs = np.array(gauss_freqs) / 1e6\n",
    "\n",
    "# iterate over FITS files\n",
    "for i, ffile in enumerate(fitsfiles):\n",
    "\n",
    "    # create output filename\n",
    "    if outdir is None:\n",
    "        output_dir = os.path.dirname(ffile)\n",
    "    else:\n",
    "        output_dir = outdir\n",
    "\n",
    "    output_fname = os.path.basename(ffile)\n",
    "    output_fname = os.path.splitext(output_fname)\n",
    "    if ext is not None:\n",
    "        output_fname = output_fname[0] + '.pbcorr{}'.format(ext) + output_fname[1]\n",
    "    else:\n",
    "        output_fname = output_fname[0] + '.pbcorr' + output_fname[1]\n",
    "    output_fname = os.path.join(output_dir, output_fname)\n",
    "\n",
    "    # check for overwrite\n",
    "    if os.path.exists(output_fname) and overwrite is False:\n",
    "        raise IOError(\"{} exists, not overwriting\".format(output_fname))\n",
    "\n",
    "    # load hdu\n",
    "    print(\"...loading {}\".format(ffile))\n",
    "    hdu = fits.open(ffile)\n",
    "\n",
    "    # get header and data\n",
    "    head = hdu[0].header\n",
    "    data = hdu[0].data\n",
    "\n",
    "    # determine if freq precedes stokes in header\n",
    "    if head['CTYPE3'] == 'FREQ':\n",
    "        freq_ax = 3\n",
    "        stok_ax = 4\n",
    "    else:\n",
    "        freq_ax = 4\n",
    "        stok_ax = 3\n",
    "\n",
    "    # get axes info\n",
    "    npix1 = head[\"NAXIS1\"]\n",
    "    npix2 = head[\"NAXIS2\"]\n",
    "    nstok = head[\"NAXIS{}\".format(stok_ax)]\n",
    "    nfreq = head[\"NAXIS{}\".format(freq_ax)]\n",
    "\n",
    "    # get polarization info\n",
    "    pol_arr = np.asarray(head[\"CRVAL{}\".format(stok_ax)] + np.arange(nstok) * head[\"CDELT{}\".format(stok_ax)], dtype=np.int)\n",
    "\n",
    "    # replace with forced polarization if provided\n",
    "    if pols is not None:\n",
    "        pol_arr = np.asarray(pols, dtype=np.int)\n",
    "\n",
    "    # set beam maps\n",
    "    beam_pols = uvb.polarization_array.tolist()\n",
    "    beam_maps = np.array([beam_maps[beam_pols.index(p)] for p in pol_arr])\n",
    "\n",
    "    # make sure required pols exist in maps\n",
    "    if not np.all([p in uvb.polarization_array for p in pol_arr]):\n",
    "        raise ValueError(\"Required polarizationns {} not found in Beam polarization array\".format(pol_arr))\n",
    "\n",
    "    # get WCS\n",
    "    w = wcs.WCS(ffile)\n",
    "\n",
    "    # convert pixel to equatorial coordinates\n",
    "    lon_arr, lat_arr = np.meshgrid(np.arange(npix1), np.arange(npix2))\n",
    "    lon, lat, s, f = w.all_pix2world(lon_arr.ravel(), lat_arr.ravel(), 0, 0, 0)\n",
    "    lon = lon.reshape(npix2, npix1)\n",
    "    lat = lat.reshape(npix2, npix1)\n",
    "\n",
    "    # convert from equatorial to spherical coordinates\n",
    "    loc = crd.EarthLocation(lat=lat_t*u.degree, lon=lon_t*u.degree)\n",
    "    time = Time(time_, format='jd', scale='utc')\n",
    "    equatorial = crd.SkyCoord(ra=lon*u.degree, dec=lat*u.degree, frame='fk5', location=loc, obstime=time)\n",
    "    altaz = equatorial.transform_to('altaz')\n",
    "    theta = np.abs(altaz.alt.value - 90.0)\n",
    "    phi = altaz.az.value\n",
    "\n",
    "    # get data frequencies\n",
    "    if freq_ax == 3:\n",
    "        data_freqs = w.all_pix2world(0, 0, np.arange(nfreq), 0, 0)[2] / 1e6\n",
    "    else:\n",
    "        data_freqs = w.all_pix2world(0, 0, 0, np.arange(nfreq), 0)[3] / 1e6\n",
    "    Ndata_freqs = len(data_freqs)\n",
    "\n",
    "    if i == 0 or a.spec_cube is False:\n",
    "        # evaluate primary beam\n",
    "        print(\"...evaluating PB\")\n",
    "        pb = beam_interp_func(theta, phi)\n",
    "\n",
    "    # interpolate primary beam onto data frequencies\n",
    "    print(\"...interpolating PB\")\n",
    "    pb_shape = (pb.shape[1], pb.shape[2])\n",
    "    pb_interp = interpolate.interp1d(beam_freqs, pb, axis=1, kind='linear', fill_value='extrapolate')(data_freqs)\n",
    "\n",
    "    # data shape is [naxis4, naxis3, naxis2, naxis1]\n",
    "    if freq_ax == 4:\n",
    "        pb_interp = np.moveaxis(pb_interp, 0, 1)\n",
    "\n",
    "    # divide or multiply by primary beam\n",
    "    if multiply is True:\n",
    "        print(\"...multiplying PB into image\")\n",
    "        data_pbcorr = data * pb_interp\n",
    "    else:\n",
    "        print(\"...dividing PB into image\")\n",
    "        data_pbcorr = data / pb_interp\n",
    "\n",
    "    # change polarization to interpolated beam pols\n",
    "    head[\"CRVAL{}\".format(stok_ax)] = pol_arr[0]\n",
    "    if len(pol_arr) == 1:\n",
    "        step = 1\n",
    "    else:\n",
    "        step = np.diff(pol_arr)[0]\n",
    "    head[\"CDELT{}\".format(stok_ax)] = step\n",
    "    head[\"NAXIS{}\".format(stok_ax)] = len(pol_arr)\n",
    "\n",
    "    print(\"...saving {}\".format(output_fname))\n",
    "    fits.writeto(output_fname, data_pbcorr, head, overwrite=True)\n",
    "\n",
    "    output_pb = output_fname.replace(\".pbcorr.\", \".pb.\")\n",
    "    print(\"...saving {}\".format(output_pb))\n",
    "    fits.writeto(output_pb, pb_interp, head, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure theta and phi make sense\n",
    "plt.figure()\n",
    "plt.plot(np.degrees(phi.flatten()),np.degrees(theta.flatten()),'.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importfits                                                                                                                           \n",
    "cmd = p.casa + [\"-c\", \"importfits('{}', '{}', overwrite={})\".format(output_fname, os.path.splitext(output_fname)[0] + '.image', p.overwrite)]\n",
    "ecode = subprocess.call(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration\n",
    "\n",
    "To be ran in CASA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print perameters\n",
    "cal_kwargs = copy.deepcopy(dict(list(algs['gen_cal'].items()) + list(algs['di_cal'].items())))\n",
    "kwargs = global_vars(varlist)\n",
    "kwargs.update(cal_kwargs)\n",
    "kwargs = dict(list(cal_kwargs.items()) + list(global_vars(varlist).items()))\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'gleam02',\n",
       " 'source_ra': 30.05,\n",
       " 'source_dec': -30.891,\n",
       " 'ex_ants': '0,2,11,14,50,98',\n",
       " 'export_gains': True,\n",
       " 'smooth': True,\n",
       " 'gp_max_dly': 200,\n",
       " 'medfilt': True,\n",
       " 'kernel': 13,\n",
       " 'bp_broad_flags': True,\n",
       " 'bp_flag_frac': 0.25,\n",
       " 'model': 'small_gleam.cl.pbcorr.image',\n",
       " 'refant': 53,\n",
       " 'rflag': False,\n",
       " 'KGcal': True,\n",
       " 'KGsnr': 0.0,\n",
       " 'Acal': True,\n",
       " 'Asnr': 0.0,\n",
       " 'BPcal': True,\n",
       " 'BPsnr': 0.0,\n",
       " 'BPsolnorm': False,\n",
       " 'uvrange': '',\n",
       " 'timerange': '',\n",
       " 'gain_spw': '',\n",
       " 'bp_spw': '',\n",
       " 'split_cal': False,\n",
       " 'split_ext': 'split',\n",
       " 'split_model': True,\n",
       " 'gain_ext': '',\n",
       " 'gaintables': '',\n",
       " 'datafile': '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/zen.2458042.45466.HH.uvR.ms',\n",
       " 'verbose': True,\n",
       " 'overwrite': True,\n",
       " 'out_dir': '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/',\n",
       " 'casa': ['casa',\n",
       "  '--nologger',\n",
       "  '--nocrashreport',\n",
       "  '--nogui',\n",
       "  '--agg',\n",
       "  '--logfile',\n",
       "  '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/skycal_out.log'],\n",
       " 'point_ra': 30.05,\n",
       " 'longitude': 21.4286,\n",
       " 'latitude': -30.7215,\n",
       " 'lf': <_io.TextIOWrapper name='/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/skycal_out.log' mode='w' encoding='UTF-8'>}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Expand sky_cal.py\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "# Calibration and Imaging Functions\n",
    "#-------------------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------------------\n",
    "# Direction Independent Calibration\n",
    "#-------------------------------------------------------------------------------\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import argparse\n",
    "import subprocess\n",
    "import shutil\n",
    "import glob\n",
    "import re\n",
    "\n",
    "Acal = True\n",
    "Asnr = 0.0\n",
    "BPcal = True\n",
    "BPsnr = 0.0\n",
    "BPsolnorm = False\n",
    "KGcal = True\n",
    "KGsnr = 0.0\n",
    "bp_broad_flags = True\n",
    "bp_flag_frac = 0.25\n",
    "bp_spw = ''\n",
    "datafile = ms_outfile#'/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/zen.2458042.45466.HH.uvR.ms'\n",
    "ex_ants = '0,2,11,14,50,98'\n",
    "export_gains = True\n",
    "gain_ext = ''\n",
    "gain_spw = ''\n",
    "gaintables = ''\n",
    "gp_max_dly = 200\n",
    "kernel = 13\n",
    "latitude = -30.7215\n",
    "#lf = <open file '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/skycal_out.log', mode 'w' at 0x11b58bd20>\n",
    "longitude = 21.4286\n",
    "medfilt = True\n",
    "model = '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/small_gleam_model.cl.pbcorr.image'\n",
    "out_dir = '/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/'\n",
    "overwrite = True\n",
    "point_ra = 30.05\n",
    "refant = '53'\n",
    "rflag = True\n",
    "smooth = True\n",
    "source = 'gleam02'\n",
    "source_dec = -30.891\n",
    "source_ra = 30.05\n",
    "split_cal = False\n",
    "split_ext = 'split'\n",
    "split_model = True\n",
    "timerange = ''\n",
    "uvrange = ''\n",
    "verbose = True\n",
    "msin= ms_outfile#'/Users/tashaleebillings/Desktop/data/NK_CASA_Pipeline/zen.2458042.45466.HH.uvR.ms'\n",
    "silence=False\n",
    "unflag=False\n",
    "bpoly=False\n",
    "degamp=4\n",
    "degphase=1\n",
    "flag_autos=False\n",
    "cal_ext=\"split\"\n",
    "model_ext=\"model\"\n",
    "gaintables=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def echo(message, type=0):\n",
    "    if verbose:\n",
    "        if type == 0:\n",
    "            print(message)\n",
    "        elif type == 1:\n",
    "            print(\"\\n\" + message + \"\\n\" + \"-\"*40)\n",
    "\n",
    "# get phase center\n",
    "if source_ra is not None and source_dec is not None:\n",
    "    _ra = source_ra / 15.0\n",
    "    ra_h = int(np.floor(_ra))\n",
    "    ra_m = int(np.floor((_ra - ra_h) * 60.))\n",
    "    ra_s = int(np.around(((_ra - ra_h) * 60. - ra_m) * 60.))\n",
    "    dec_d = int(np.floor(np.abs(source_dec)) * source_dec / np.abs(source_dec))\n",
    "    dec_m = int(np.floor(np.abs(source_dec - dec_d) * 60.))\n",
    "    dec_s = int(np.abs(source_dec - dec_d) * 3600. - dec_m * 60.)\n",
    "    fixdir = \"J2000 {:02d}h{:02d}m{:02.0f}s {:03d}d{:02d}m{:02.0f}s\".format(ra_h, ra_m, ra_s, dec_d, dec_m, dec_s)\n",
    "else:\n",
    "    fixdir = None\n",
    "\n",
    "#msin = msin\n",
    "\n",
    "# get paths\n",
    "base_ms = os.path.basename(msin)\n",
    "if out_dir is None:\n",
    "    out_dir = os.path.dirname(msin)\n",
    "else:\n",
    "    out_dir = out_dir\n",
    "\n",
    "# check for uvfits\n",
    "if base_ms.split('.')[-1] == 'uvfits':\n",
    "    echo(\"...converting uvfits to ms\", type=1)\n",
    "    uvfits = msin\n",
    "    msin = os.path.join(out_dir, '.'.join(base_ms.split('.')[:-1] + ['ms']))\n",
    "    base_ms = os.path.basename(msin)\n",
    "    msfiles = glob.glob(\"{}*\".format(msin))\n",
    "    if len(msfiles) != 0:\n",
    "        for i, msf in enumerate(msfiles):\n",
    "            try:\n",
    "                os.remove(msf)\n",
    "            except OSError:\n",
    "                shutil.rmtree(msf)\n",
    "    echo(\"writing {}\".format(msin))\n",
    "    importuvfits(uvfits, msin)\n",
    "\n",
    "# get antenna name to station mapping\n",
    "tb.open(\"{}/ANTENNA\".format(msin))\n",
    "antstn = tb.getcol(\"STATION\")\n",
    "tb.close()\n",
    "antstn = [stn for stn in antstn if stn != '']\n",
    "antids = [re.findall('\\d+', stn)[0] for stn in antstn]\n",
    "antid2stn = dict(zip(antids, antstn))\n",
    "\n",
    "# configure refant\n",
    "if refant is None and (KGcal is True or Acal is True or BPcal is True):\n",
    "    raise AttributeError(\"if calibrating, refant needs to be specified\")\n",
    "if refant is not None:\n",
    "    refants = [antid2stn[ra] for ra in refant.split(',') if ra in antid2stn]\n",
    "\n",
    "# rephase to source\n",
    "if fixdir is not None:\n",
    "    echo(\"...fix vis to {}\".format(fixdir), type=1)\n",
    "    fixvis(msin, msin, phasecenter=fixdir)\n",
    "\n",
    "# insert source model\n",
    "if model is None:\n",
    "    if KGcal is True or Acal is True or BPcal is True:\n",
    "        print(\"...Warning: Asking to calibrate but no model image or component list provided.\")\n",
    "else:\n",
    "    if os.path.splitext(model)[1] == '.cl':\n",
    "        echo(\"...inserting component list {} as MODEL\".format(model), type=1)\n",
    "        ft(msin, complist=model, usescratch=True)\n",
    "    else:\n",
    "        echo(\"...inserting image {} as MODEL\".format(model), type=1)\n",
    "        ft(msin, model=model, usescratch=True)\n",
    "\n",
    "# unflag\n",
    "if unflag is True:\n",
    "    echo(\"...unflagging\", type=1)\n",
    "    flagdata(msin, mode='unflag')\n",
    "\n",
    "# flag autocorrs\n",
    "if flag_autos:\n",
    "    echo(\"...flagging autocorrs\", type=1)\n",
    "    flagdata(msin, autocorr=True)\n",
    "\n",
    "# flag bad ants\n",
    "if ex_ants is not None:\n",
    "    ex_ants = ','.join([antid2stn[xa] for xa in ex_ants.split(',') if xa in antid2stn])\n",
    "    echo(\"...flagging bad ants: {}\".format(ex_ants), type=1)\n",
    "    flagdata(msin, mode='manual', antenna=ex_ants)\n",
    "\n",
    "# rflag\n",
    "if rflag is True:\n",
    "    echo(\"...rfi flagging\", type=1)\n",
    "    flagdata(msin, mode='rflag')\n",
    "\n",
    "def make_cal(cal):\n",
    "    if gain_ext != '':\n",
    "        c = os.path.join(out_dir, '.'.join([base_ms, gain_ext, '{}.cal'.format(cal)]))\n",
    "    else:\n",
    "        c = os.path.join(out_dir, '.'.join([base_ms, '{}.cal'.format(cal)]))\n",
    "    return c\n",
    "\n",
    "def KGCAL(msin, gaintables=[]):\n",
    "    ## perform per-antenna delay and phase calibration ##\n",
    "    # setup calibration tables    \n",
    "    kc = make_cal('K')\n",
    "    gpc = make_cal('Gphs') \n",
    "\n",
    "    # perform initial K calibration (per-antenna delay)\n",
    "    echo(\"...performing K gaincal\", type=1)\n",
    "    if os.path.exists(kc):\n",
    "        shutil.rmtree(kc)\n",
    "    if os.path.exists(\"{}.png\".format(kc)):\n",
    "        os.remove(\"{}.png\".format(kc))\n",
    "    # iterate calibration over refants\n",
    "    for ra in refants:\n",
    "        gaincal(msin, caltable=kc+'_{}'.format(ra), gaintype=\"K\", solint='inf', refant=ra, minsnr=KGsnr,\n",
    "                spw=gain_spw, gaintable=gaintables, timerange=cal_timerange, uvrange=uvrange)\n",
    "    # merge delay solutions\n",
    "    kc_files = sorted(glob.glob(\"{}_*\".format(kc)))\n",
    "    for i, kcf in enumerate(kc_files):\n",
    "        tb.open(kcf)\n",
    "        if i == 0:\n",
    "            delays = tb.getcol('FPARAM')\n",
    "            delay_ants = tb.getcol('ANTENNA1')\n",
    "            delay_flags = tb.getcol('FLAG')\n",
    "            delay_wgts = (~delay_flags).astype(np.float)\n",
    "        else:\n",
    "            dlys = tb.getcol('FPARAM')\n",
    "            dly_ants = tb.getcol('ANTENNA1')\n",
    "            flgs = tb.getcol('FLAG')\n",
    "            wgts = (~flgs).astype(np.float)\n",
    "\n",
    "            delays = (delays*delay_wgts + dlys*wgts) / (delay_wgts + wgts).clip(1e-10, np.inf)\n",
    "            delay_flags = delay_flags * flgs\n",
    "            delay_wgts = (~delay_flags).astype(np.float)\n",
    "        tb.close()\n",
    "    shutil.copytree(kc_files[0], kc)\n",
    "    tb.open(kc, nomodify=False)\n",
    "    tb.putcol(\"FPARAM\", delays)\n",
    "    tb.putcol(\"FLAG\", delay_flags)\n",
    "    tb.close()\n",
    "    for kcf in kc_files:\n",
    "        shutil.rmtree(kcf)\n",
    "    # plot cal\n",
    "    plotcal(kc, xaxis='antenna', yaxis='delay', figfile='{}.png'.format(kc), showgui=False)\n",
    "    # append to gaintables\n",
    "    gaintables.append(kc)\n",
    "    # write delays as npz file\n",
    "    tb.open(kc)\n",
    "    delays = tb.getcol('FPARAM')\n",
    "    delay_ants = tb.getcol('ANTENNA1')\n",
    "    delay_flags = tb.getcol('FLAG')\n",
    "    tb.close()\n",
    "    np.savez(\"{}.npz\".format(kc), delay_ants=delay_ants, delays=delays, delay_flags=delay_flags, shape='(Npol, Nfreq, Nant)')\n",
    "    echo(\"...Solved for {} antenna delays\".format(np.sum(~delay_flags)))\n",
    "    echo(\"...Saving delays to {}.npz\".format(kc))\n",
    "    echo(\"...Saving plotcal to {}.png\".format(kc))\n",
    "\n",
    "    # perform initial G calibration for phase (per-spw and per-pol gain)\n",
    "    echo(\"...performing G gaincal for phase\", type=1)\n",
    "    if os.path.exists(gpc):\n",
    "        shutil.rmtree(gpc)\n",
    "    if os.path.exists(\"{}.png\".format(gpc)):\n",
    "        os.remove(\"{}.png\".format(gpc))\n",
    "    gaincal(msin, caltable=gpc, gaintype='G', solint='inf', refant=refant, minsnr=KGsnr, calmode='p',\n",
    "            spw=gain_spw, gaintable=gaintables, timerange=cal_timerange, uvrange=uvrange)\n",
    "    plotcal(gpc, xaxis='antenna', yaxis='phase', figfile='{}.png'.format(gpc), showgui=False)\n",
    "    gaintables.append(gpc)\n",
    "\n",
    "    # write phase to file\n",
    "    tb.open(gpc)\n",
    "    phases = np.angle(tb.getcol('CPARAM'))\n",
    "    phase_ants = tb.getcol('ANTENNA1')\n",
    "    phase_flags = tb.getcol('FLAG')\n",
    "    tb.close()\n",
    "    np.savez(\"{}.npz\".format(gpc), phase_ants=phase_ants, phases=phases, phase_flags=phase_flags, shape='(Npol, Nfreq, Nant)')\n",
    "    echo(\"...Solved for {} antenna phases\".format(np.sum(~phase_flags)))\n",
    "    echo(\"...Saving phases to {}.npz\".format(gpc))\n",
    "    echo(\"...Saving plotcal to {}.png\".format(gpc))\n",
    "\n",
    "    return gaintables\n",
    "\n",
    "def ACAL(msin, gaintables=[]):\n",
    "    # gaincal G amplitude\n",
    "    echo(\"...performing G gaincal for amplitude\", type=1)\n",
    "    gac = make_cal(\"Gamp\")\n",
    "\n",
    "    if os.path.exists(gac):\n",
    "        shutil.rmtree(gac)\n",
    "    if os.path.exists(\"{}.png\".format(gac)):\n",
    "        os.remove(\"{}.png\".format(gac))\n",
    "    gaincal(msin, caltable=gac, gaintype='G', solint='inf', refant=refant, minsnr=Asnr, calmode='a',\n",
    "            spw=gain_spw, gaintable=gaintables, timerange=cal_timerange, uvrange=uvrange)\n",
    "    plotcal(gac, xaxis='antenna', yaxis='amp', figfile='{}.png'.format(gac), showgui=False)\n",
    "    gaintables.append(gac)\n",
    "\n",
    "    # write amp to file\n",
    "    tb.open(gac)\n",
    "    amps = np.abs(tb.getcol('CPARAM'))\n",
    "    amp_ants = tb.getcol('ANTENNA1')\n",
    "    amp_flags = tb.getcol('FLAG')\n",
    "    tb.close()\n",
    "    np.savez(\"{}.npz\".format(gac), amp_ants=amp_ants, amps=amps, amp_flags=amp_flags, shape='(Npol, Nfreq, Nant)')\n",
    "    echo(\"...Solved for {} antenna amps\".format(np.sum(~amp_flags)))\n",
    "    echo(\"...Saving amps to {}.npz\".format(gac))\n",
    "    echo('...Saving G amp plotcal to {}.png'.format(gac))\n",
    "\n",
    "    return gaintables\n",
    "\n",
    "def BPCAL(msin, gaintables=[]):\n",
    "    # calibrated bandpass\n",
    "    echo(\"...performing B bandpass cal\", type=1)\n",
    "    bc = make_cal(\"B\")\n",
    "\n",
    "    Btype = \"B\"\n",
    "    if bpoly:\n",
    "        Btype=\"BPOLY\"\n",
    "    if os.path.exists(bc):\n",
    "        shutil.rmtree(bc)\n",
    "    if os.path.exists(\"{}.amp.png\".format(bc)):\n",
    "        os.remove(\"{}.amp.png\".format(bc))\n",
    "    if os.path.exists(\"{}.phs.png\".format(bc)):\n",
    "        os.remove(\"{}.phs.png\".format(bc))\n",
    "    bandpass(vis=msin, spw=bp_spw, minsnr=BPsnr, bandtype=Btype, degamp=degamp, degphase=degphase,\n",
    "            caltable=bc, gaintable=gaintables, solint='inf', refant=refant, timerange=cal_timerange,\n",
    "            uvrange=uvrange, solnorm=BPsolnorm)\n",
    "    plotcal(bc, xaxis='chan', yaxis='amp', figfile=\"{}.amp.png\".format(bc), showgui=False)\n",
    "    plotcal(bc, xaxis='chan', yaxis='phase', figfile=\"{}.phs.png\".format(bc), showgui=False)\n",
    "    gaintables.append(bc)\n",
    "\n",
    "    # write bp to file\n",
    "    if bpoly is False:\n",
    "        # get flags and bandpass data\n",
    "        tb.open(bc)\n",
    "        bp = tb.getcol('CPARAM')\n",
    "        bp_ants = tb.getcol(\"ANTENNA1\")\n",
    "        bp_flags = tb.getcol('FLAG')\n",
    "        tb.close()\n",
    "        # load spectral window data\n",
    "        tb.open(bc+\"/SPECTRAL_WINDOW\")\n",
    "        bp_freqs = tb.getcol(\"CHAN_FREQ\")\n",
    "        tb.close()\n",
    "        # write to file\n",
    "        np.savez(\"{}.npz\".format(bc), bp=bp, bp_ants=bp_ants, bp_flags=bp_flags, bp_freqs=bp_freqs, shape='(Npol, Nfreq, Nant)')\n",
    "        echo(\"...Solved for {} antenna bandpasses\".format(np.sum(~bp_flags)))\n",
    "        echo(\"...Saving bandpass to {}.npz\".format(bc))\n",
    "        echo(\"...Saving amp plotcal to {}.amp.png\".format(bc))\n",
    "        echo(\"...Saving phs plotcal to {}.phs.png\".format(bc))\n",
    "    else:\n",
    "        echo(\"NOTE: Writing BPOLY bandpass solutions to .npz file not currently supported.\")\n",
    "\n",
    "    return gaintables\n",
    "\n",
    "## Begin Calibration ##\n",
    "# init cal_timerange\n",
    "cal_timerange = ','.join(timerange)\n",
    "\n",
    "# run through various calibration options\n",
    "#gaintables = gaintables\n",
    "if KGcal:\n",
    "    gaintables = KGCAL(msin, gaintables)\n",
    "\n",
    "if Acal:\n",
    "    gaintables = ACAL(msin, gaintables)\n",
    "\n",
    "if BPcal:\n",
    "    gaintables = BPCAL(msin, gaintables)\n",
    "\n",
    "# apply calibration gaintables\n",
    "if len(gaintables) > 0:\n",
    "    echo(\"...applying gaintables: \\n {}\".format('\\n'.join(gaintables)), type=1)\n",
    "    applycal(msin, gaintable=gaintables)\n",
    "\n",
    "    # split cal\n",
    "    if split_cal:\n",
    "        # split MS\n",
    "        ms_split = os.path.join(out_dir, \"{}.{}\".format(base_ms, cal_ext))\n",
    "        files = glob.glob(\"{}*\".format(ms_split))\n",
    "        for f in files:\n",
    "            if os.path.exists(f):\n",
    "                try:\n",
    "                    shutil.rmtree(f)\n",
    "                except OSError:\n",
    "                    os.remove(f)\n",
    "\n",
    "        echo(\"...splitting CORRECTED of {} into {}\".format(msin, ms_split))\n",
    "        split(msin, ms_split, datacolumn=\"corrected\")\n",
    "else:\n",
    "    echo(\"...no calibration performed\", type=1)\n",
    "\n",
    "if split_model:\n",
    "    # split MS\n",
    "    ms_split = os.path.join(out_dir, \"{}.{}\".format(base_ms, model_ext))\n",
    "    files = glob.glob(\"{}*\".format(ms_split))\n",
    "    for f in files:\n",
    "        if os.path.exists(f):\n",
    "            try:\n",
    "                shutil.rmtree(f)\n",
    "            except OSError:\n",
    "                os.remove(f)\n",
    "    echo(\"...splitting MODEL of {} into {}\".format(msin, ms_split))\n",
    "    split(msin, ms_split, datacolumn=\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end block\n",
    "time2 = datetime.utcnow()\n",
    "utils.log(\"...finished DI_CAL: {:d} sec elapsed\".format(utils.get_elapsed_time(time, time2)), f=lf, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather gaintables\n",
    "gext = ''\n",
    "if gain_ext not in ['', None]:\n",
    "    gext = '.{}'.format(gain_ext)\n",
    "gts = sorted(glob.glob(\"{}{}.?.cal\".format(datafile, gext)) + glob.glob(\"{}{}.????.cal\".format(datafile, gext)))\n",
    "\n",
    "utils.log(\"...exporting\\n{}\\n to calfits and combining into a single cal table\".format('\\n'.join(gts)), f=lf, verbose=verbose)\n",
    "# do file checks\n",
    "mirvis = os.path.splitext(datafile)[0]\n",
    "gtsnpz = [\"{}.npz\".format(gt) for gt in gts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  EXPORT TO CALFITS\n",
    "\n",
    "Simply run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to calfits if desired\n",
    "if not os.path.exists(mirvis):\n",
    "    utils.log(\"...{} doesn't exist: cannot export gains to calfits\".format(mirvis), f=lf, verbose=verbose)\n",
    "\n",
    "elif len(gts) == 0:\n",
    "    utils.log(\"...no gaintables found, cannot export gains to calfits\", f=lf, verbose=verbose)\n",
    "\n",
    "elif not np.all([os.path.exists(gtnpz) for gtnpz in gtsnpz]):\n",
    "    utils.log(\"...couldn't find a .npz file for all input .cal tables, can't export to calfits\", f=lf, verbose=verbose)\n",
    "\n",
    "else:\n",
    "    calfits_fname = \"{}.{}{}.calfits\".format(os.path.basename(mirvis), source, gain_ext)\n",
    "    cmd = ['python','/Users/tashaleebillings/casa_imaging/scripts/skynpz2calfits.py', \"--fname\", calfits_fname, \"--uv_file\", mirvis, '--out_dir', out_dir]\n",
    "    if overwrite:\n",
    "        cmd += [\"--overwrite\"]\n",
    "    # add a delay and phase solution\n",
    "    matchK = [\"K.cal.npz\" in gt for gt in gtsnpz]\n",
    "    matchGphs = [\"Gphs.cal.npz\" in gt for gt in gtsnpz]\n",
    "    if np.any(matchK):\n",
    "        cmd += [\"--plot_dlys\"]\n",
    "        cmd += [\"--dly_files\"] + [gtsnpz[i] for i, b in enumerate(matchK) if b == True]\n",
    "        if not np.any(matchGphs):\n",
    "            utils.log(\"...WARNING: A delay file {} was found, but no mean phase file, which is needed if a delay file is present.\", f=lf, verbose=verbose)\n",
    "    if np.any(matchGphs):\n",
    "        cmd += [\"--plot_phs\"]\n",
    "        cmd += [\"--phs_files\"] + [gtsnpz[i] for i, b in enumerate(matchGphs) if b == True]\n",
    "\n",
    "    # add a mean amp solution\n",
    "    matchGamp = [\"Gamp.cal.npz\" in gt for gt in gtsnpz]\n",
    "    if np.any(matchGamp):\n",
    "        cmd += [\"--plot_amp\"]\n",
    "        cmd += [\"--amp_files\"] + [gtsnpz[i] for i, b in enumerate(matchGamp) if b == True]\n",
    "\n",
    "    # add a bandpass solution\n",
    "    matchB = [\"B.cal.npz\" in gt for gt in gtsnpz]\n",
    "    if np.any(matchB):\n",
    "        cmd += [\"--plot_bp\"]\n",
    "        cmd += [\"--bp_files\"] + [gtsnpz[i] for i, b in enumerate(matchB) if b == True]\n",
    "\n",
    "    # additional smoothing options\n",
    "    if smooth:\n",
    "        cmd += [\"--bp_gp_smooth\", \"--bp_gp_max_dly\", gp_max_dly]\n",
    "    if medfilt:\n",
    "        cmd += [\"--bp_medfilt\", \"--medfilt_kernel\", kernel]\n",
    "    if bp_broad_flags:\n",
    "        cmd += [\"--bp_broad_flags\", \"--bp_flag_frac\", bp_flag_frac]\n",
    "    if not verbose:\n",
    "        cmd += ['--silence']\n",
    "\n",
    "    cmd = map(str, cmd)\n",
    "    ecode = subprocess.call(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert CALFITS Back to Btotal.cal\n",
    "\n",
    "I directly ran \"calfits_to_Bcal.py\" in CASA to convert the new calibration solutions from NPZ format to calfits format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert calfits back to a single Btotal.cal table\n",
    "# Run with casa as: casa -c calfits_to_Bcal.py <args>\n",
    "import pyfits\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "# Set Arguments\n",
    "bfile_ = gts[matchB.index(True)]\n",
    "btot_file_ = os.path.join(out_dir, \"{}{}.Btotal.cal\".format(os.path.basename(datafile), gext))\n",
    "cfits_ = os.path.join(out_dir, calfits_fname)\n",
    "inp_cfile_ = bfile\n",
    "out_cfile_ = btot_file\n",
    "overwrite_ = True\n",
    "\n",
    "\n",
    "def calfits_to_Bcal(cfits, inp_cfile, out_cfile=None, overwrite=False):\n",
    "    \"\"\"\n",
    "    Take a calfits antenna gain file and insert data into an existing\n",
    "    CASA bandpass calibration table. Note that due to the obtuseness of CASA,\n",
    "    this function is VERY rigid: the calfits file must be very similar in shape\n",
    "    and order to the CASA Bcal table.\n",
    "    It is only recommended to use this script on calfits files that were originally\n",
    "    *B.cal tables, exported to B.cal.npz files by sky_cal.py and then converted to\n",
    "    calfits via skynpz2calfits.py.\n",
    "    Args:\n",
    "        cfits : str, filepath to pyuvdata calfits file\n",
    "        inp_cfile : str, filepath to CASA Bandpass calibration table to use as a template\n",
    "        out_cfile : str, filepath for output CASA Bcal table with cfits data\n",
    "        overwrite : bool, if True, overwrite output Bcal table\n",
    "    \"\"\"\n",
    "    # assert IO\n",
    "    if out_cfile is None:\n",
    "        out_cfile = inp_cfile        \n",
    "    if os.path.exists(out_cfile) and not overwrite:\n",
    "        raise IOError(\"Output cal table {} exists and overwrite is False...\".format(out_cfile))\n",
    "\n",
    "    # move inp_cfile to out_cfile\n",
    "    if os.path.exists(out_cfile):\n",
    "        shutil.rmtree(out_cfile)\n",
    "    shutil.copytree(inp_cfile, out_cfile)\n",
    "\n",
    "    # load cfits data and get metadata\n",
    "    hdu = pyfits.open(cfits)\n",
    "    head = hdu[0].header\n",
    "    data = hdu[0].data\n",
    "\n",
    "    # open out_cfile descriptor\n",
    "    tb.open(out_cfile)\n",
    "    assert \"CPARAM\" in tb.getdminfo()['*1']['COLUMNS'], \"{} is not a CASA bandpass table...\".format(inp_cfile)\n",
    "    d = tb.getcol(\"CPARAM\")\n",
    "    f = tb.getcol(\"FLAG\")\n",
    "    a = tb.getcol(\"ANTENNA1\")\n",
    "\n",
    "    # The pol axes must match in size\n",
    "    assert head['NAXIS2'] == d.shape[0], \"Npols doesn't match between {} and {}\".format(inp_cfile, cfits)\n",
    "\n",
    "    # real and imag are 0, 1 Image Array axes of fits file\n",
    "    flags = data[:, 0, :, :, :, 2]\n",
    "    data = data[:, 0, :, :, :, 0].astype(np.complex) - 1j * data[:, 0, :, :, :, 1]  # CASA conjugates cal solutions...\n",
    "\n",
    "    # extend to matching antennas\n",
    "    Nants, Nfreqs, Ntimes, Npols = data.shape\n",
    "    ants = hdu[1].data['ANTARR'].astype(np.int).tolist()\n",
    "    _data, _flags = [], []\n",
    "    for i, ant in enumerate(a):\n",
    "        if ant in ants:\n",
    "            aind = ants.index(ant)\n",
    "            _data.append(data[aind])\n",
    "            _flags.append(flags[aind])\n",
    "        else:\n",
    "            _data.append(np.ones((Nfreqs, Ntimes, Npols), dtype=np.complex))\n",
    "            _flags.append(np.ones((Nfreqs, Ntimes, Npols), dtype=np.float))\n",
    "    data = np.asarray(_data, dtype=np.complex)\n",
    "    flags = np.asarray(_flags, dtype=np.float)    \n",
    "\n",
    "    # cal table is ordered as ant1_time1, ant2_time1, ... ant1_time2, ant2_time2\n",
    "    Nants, Nfreqs, Ntimes, Npols = data.shape\n",
    "    data = np.moveaxis(data, 2, 0).reshape(Nants * Ntimes, Nfreqs, Npols).T\n",
    "    flags = np.moveaxis(flags, 2, 0).reshape(Nants * Ntimes, Nfreqs, Npols).T\n",
    "\n",
    "    # now select frequencies that match cal table\n",
    "    tb.close()\n",
    "    tb.open(\"{}/SPECTRAL_WINDOW\".format(out_cfile))\n",
    "    fr = tb.getcol(\"CHAN_FREQ\")[:, 0]\n",
    "    tb.close()\n",
    "    freqs = np.arange(head[\"NAXIS4\"]) * head[\"CDELT4\"] + head[\"CRVAL4\"]\n",
    "    fselect = np.array([np.isclose(_f, fr).any() for _f in freqs])\n",
    "    data = data[:, fselect, :]\n",
    "    flags = flags[:, fselect, :]\n",
    "\n",
    "    # the two arrays must match in shape now\n",
    "    assert data.shape == d.shape, \"fits_data.shape != cal_data.shape...\"\n",
    "    assert flags.shape == f.shape, \"fits_flags.shape != cal_flags.shape...\"\n",
    "\n",
    "    # putcol\n",
    "    print(\"...inserting {} data and flags into {}\".format(cfits, out_cfile))\n",
    "    tb.open(out_cfile, nomodify=False)\n",
    "    tb.putcol(\"CPARAM\", data)\n",
    "    tb.putcol(\"FLAG\", flags)\n",
    "    tb.close()\n",
    "\n",
    "    return out_cfile\n",
    "\n",
    "# run script\n",
    "calfits_to_Bcal(cfits=cfits_, inp_cfile=inp_cfile_, out_cfile=out_cfile_, overwrite=overwrite_)\n",
    "gts = [btot_file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append to gaintables\n",
    "gtables=gaintables\n",
    "gtables += gts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Image\n",
    "\n",
    "You should run this in CASA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = datetime.utcnow()\n",
    "utils.log(\"\\n{}\\n...Starting DI_IMG: {}\\n\".format(\"-\"*60, time), f=lf, verbose=verbose)\n",
    "img_kwargs = copy.deepcopy(dict(list(algs['di_img'].items())))    \n",
    "utils.log(json.dumps(img_kwargs, indent=1) + '\\n', f=lf, verbose=verbose)\n",
    "\n",
    "left_arg,right_arg = zip(*img_kwargs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('image_mfs', True),\n",
       " ('image_mdl', False),\n",
       " ('image_res', False),\n",
       " ('source_ext', ''),\n",
       " ('niter', [100, 100]),\n",
       " ('threshold', ['0Jy']),\n",
       " ('cycleniter', [1000]),\n",
       " ('mask', ['clean_reg1.crtf', '']),\n",
       " ('weighting', 'briggs'),\n",
       " ('robust', -1),\n",
       " ('uvrange', ''),\n",
       " ('pxsize', 300),\n",
       " ('imsize', 512),\n",
       " ('spw', '0:100~924'),\n",
       " ('stokes', 'XXYY'),\n",
       " ('timerange', ''),\n",
       " ('deconvolver', 'hogbom'),\n",
       " ('gridder', 'standard'),\n",
       " ('wpplanes', 1),\n",
       " ('pblimit', -1),\n",
       " ('image_spec', False),\n",
       " ('image_mdl_spec', False),\n",
       " ('spec_start', 0),\n",
       " ('spec_end', 1024),\n",
       " ('spec_dchan', 250),\n",
       " ('source_extract', True),\n",
       " ('pols', [-5, -6]),\n",
       " ('radius', 1),\n",
       " ('gauss_mult', 1.5),\n",
       " ('plot_fit', False)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(algs['di_img'].items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print var and then copy them to the cell below\n",
    "for idx in range(len(left_arg)):\n",
    "    print(left_arg[idx], end=\"=\")\n",
    "    print(right_arg[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_stem_ = os.path.splitext(ms_outfile)[0]\n",
    "msin_ = ms_outfile\n",
    "#pxsize_=500\n",
    "imsize_=512\n",
    "spw_='0:100~924'\n",
    "stokes_='XXYY'\n",
    "timerange_=''\n",
    "deconvolver_='hogbom'\n",
    "gridder_='standard'\n",
    "wpplanes_=1\n",
    "pblimit_=-1\n",
    "\n",
    "spec_start_=0\n",
    "spec_end_=1024\n",
    "spec_dchan_=250\n",
    "\n",
    "# MFS CLEAN\n",
    "\n",
    "\"\"\" \n",
    "    MFS Imaging Function via CLEAN task.\n",
    "    d should be a dictionary holding all required parameters\n",
    "    from the argparser\n",
    "\"\"\" \n",
    "log(\"...cleaning {} for {} iters with mask '{}'\".format(msin_, niter_, mask_))\n",
    "clean(vis=msin_,imagename=im_stem_+'_',niter =0,weighting = 'briggs',robust =0,imsize =[imsize_ ,imsize_],\n",
    "      cell=['500 arcsec'] ,mode='mfs',nterms =1,spw=spw_,stokes=stokes_)\n",
    "log(\"...saving {}\".format('{}.image'.format(im_stem_)))\n",
    "exportfits(imagename='{}.image'.format(im_stem_), \n",
    "           fitsimage='{}.image.fits'.format(im_stem_), stokeslast=False, overwrite=True)\n",
    "log(\"...saving {}\".format('{}.image.fits'.format(im_stem_)))\n",
    "\n",
    "log(\"...making spectrum\")\n",
    "clean(vis=msin_,imagename=\"spectrum_\"+im_stem_,niter=0,weighting = 'briggs',robust =0,imsize =[512 ,512]\n",
    "      ,cell=['500 arcsec'],mode='channel',nterms =niter_,spw='0',nchan=spec_end_, start=spec_start_, width=1\n",
    "      ,stokes=stokes_, threshold=threshold_,gridder=gridder_)\n",
    "\n",
    "exportfits(imagename='{}.image'.format(\"spectrum_\"+im_stem_), \n",
    "           fitsimage='{}.image.fits'.format(\"spectrum_\"+im_stem_)) \n",
    "log(\"...saving {}\".format('{}.image.fits'.format(\"spectrum_\"+im_stem_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, sys\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "gleamfile = '/Users/tashaleebillings/casa_imaging/casa_imaging/data/small_gleam.fits'\n",
    "hdu = fits.open(gleamfile)\n",
    "data = hdu[1].data\n",
    "data_ra = data[\"RAJ2000\"].copy() # 1D array\n",
    "data_dec = data[\"DEJ2000\"].copy() # 1D array\n",
    "\n",
    "print(data)\n",
    "print(hdu[1].header)\n",
    "\n",
    "gleamfile1=\"/Users/tashaleebillings/Desktop/data/randsrc_airybeam_Nsrc100_fullband_fullStokesModel.model.fits\"\n",
    "hdu1 = fits.open(gleamfile1)\n",
    "print(hdu1[0].header)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
